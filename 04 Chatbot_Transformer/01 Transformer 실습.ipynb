{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n인코더 Input : 최대 길이만큼 <PAD>\\n디코더 Input : 시작을 알리는 <SOS>\\n디코더 타겟 : 끝을 알리는 <END>\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''전처리 결과'''\n",
    "seed = 99\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# 인코더의 입력값\n",
    "index_inputs = np.load(open('data_in/train_inputs.npy','rb'), allow_pickle=True)\n",
    "# 디코더의 입력값\n",
    "index_outputs = np.load(open('data_in/train_outputs.npy','rb'), allow_pickle=True)\n",
    "# 디코더의 타깃값\n",
    "index_targets = np.load(open('data_in/train_targets.npy','rb'), allow_pickle=True)\n",
    "# dictonary\n",
    "prepro_configs = json.load(open('data_in/data_configs.json'))\n",
    "\n",
    "'''\n",
    "인코더 Input : 최대 길이만큼 <PAD>\n",
    "디코더 Input : 시작을 알리는 <SOS>\n",
    "디코더 타겟 : 끝을 알리는 <END>\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2  # set을 키워보자 -> NoneType 에러가 발생한다. - 메모리이슈\n",
    "MAX_SEQUENCE =25\n",
    "EPOCH =30\n",
    "UNITS =1024\n",
    "EMBEDDING_DIM = 256\n",
    "VALIDATION_SPLIT = 0.1\n",
    "\n",
    "char2idx = prepro_configs['char2idx']\n",
    "idx2char = prepro_configs['idx2char']\n",
    "std_index = prepro_configs['std_symbol']\n",
    "end_index = prepro_configs['end_symbol']\n",
    "vocab_size = prepro_configs['vocab_size']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "스케일 내적 어텐션\n",
    "softmax(Q,k/크기)*value\n",
    "Scaling을 해주는 이유는 query, value를 이용해 내적한 값이 벡터 차원이 커지면\n",
    "학습이 잘 안될 수도 있기 때문에 벡터 크기에 따라 값이 반비례하도록 크기를 조정함\n",
    "\n",
    "\n",
    "'''\n",
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
    "\n",
    "def create_look_ahead_mask(size):\n",
    "    mask= 1 - tf.linalg.band_part(tf.ones((size,size)),-1,0)\n",
    "    return mask\n",
    "def create_masks(inp, tar):\n",
    "    # Encoder padding mask\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 2nd attention block in the decoder.\n",
    "    # This padding mask is used to mask the encoder outputs.\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 1st attention block in the decoder.\n",
    "    # It is used to pad and mask future tokens in the input received by \n",
    "    # the decoder.\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "\n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask\n",
    "\n",
    "def scaled_dot_product_attention(q,k,v,mask=None):\n",
    "    matmul_qk = tf.matmul(q,k,transpose_b = True)\n",
    "    dk = tf.cast(tf.shape(k)[-1],tf.float32) # Type을 변환함\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "    \n",
    "    if mask is not None:\n",
    "#         print(scaled_attention_logits)\n",
    "#         print(mask)\n",
    "        # scaled_attention_logits 이 상삼각행렬이 0인가?\n",
    "        scaled_attention_logits += (mask * -1e9) # 마스킹 대상에  모두 작은 음수값을 넣는 것  매우 작아지는구나\n",
    "#         print(scaled_attention_logits)\n",
    "    \n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis = -1)\n",
    "    output = tf.matmul(attention_weights,v)\n",
    "    \n",
    "    return output, attention_weights\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       " array([[1.      , 2.      , 3.      ],\n",
       "        [2.999998, 3.999998, 4.999998],\n",
       "        [5.      , 6.      , 7.      ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       " array([[1.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "        [9.5992834e-07, 9.9999905e-01, 0.0000000e+00],\n",
       "        [8.8453794e-19, 9.4049879e-10, 1.0000000e+00]], dtype=float32)>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "x=[[1.,2.,3.],[3.,4.,5],[5.,6.,7.]]\n",
    "mask = create_look_ahead_mask(3)\n",
    "scaled_dot_product_attention(x,x,x,mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "멀티 헤드 어텐션 \n",
    "'''\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self,**kargs):\n",
    "        super(MultiHeadAttention,self).__init__()\n",
    "        self.num_heads = kargs['num_heads']\n",
    "        self.d_model = kargs['d_model']\n",
    "        \n",
    "        # d_model : Q,K,V 차원을 결정하는 Parameter\n",
    "        # num_heads : 어텐션 head 수를 결정하는 parameter\n",
    "        # assert는 아래 조건에 해당하지 않으면 에러를 발생시킴\n",
    "        assert self.d_model % self.num_heads ==0 # 나머지가 없어야한다.\n",
    "        \n",
    "        self.depth = self.d_model // self.num_heads #각 Head에 입력될 벡터 차원 수\n",
    "        \n",
    "        self.wq = tf.keras.layers.Dense(kargs['d_model'])\n",
    "        self.wk = tf.keras.layers.Dense(kargs['d_model'])\n",
    "        self.wv = tf.keras.layers.Dense(kargs['d_model'])\n",
    "        \n",
    "        self.dense = tf.keras.layers.Dense(kargs['d_model'])\n",
    "        \n",
    "    def split_heads(self, x, batch_size): # 학습 중에 배치 크기가 바뀔 수 있음.\n",
    "        # (batch, sequence, feature) → (batch, head, sequence, feature)\n",
    "        x = tf.reshape(x, (batch_size,-1,self.num_heads,self.depth))\n",
    "        return tf.transpose(x, perm = [0,2,1,3]) # Sequence, head 차원을 바꿈\n",
    "    \n",
    "    def call(self, v, k, q, mask=None):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "        \n",
    "        q= self.wq(q)\n",
    "        k= self.wk(k)\n",
    "        v = self.wv(v)\n",
    "        \n",
    "        q = self.split_heads(q,batch_size)\n",
    "        k = self.split_heads(k,batch_size)\n",
    "        v = self.split_heads(v,batch_size)\n",
    "        \n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(q,k,v,mask)\n",
    "        \n",
    "        scaled_attention = tf.transpose(scaled_attention, perm = [0,2,1,3]) # (batch, seq, feature) 차원\n",
    "        # feature \n",
    "        concat_attention = tf.reshape(scaled_attention,(batch_size,-1, self.d_model))\n",
    "        \n",
    "        output = self.dense(concat_attention) # 멀티헤드 어텐션 벡터 \n",
    "        \n",
    "        return output, attention_weights\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Position-wise FFNN\n",
    "'''\n",
    "def point_wise_feed_forward_network(**kargs):\n",
    "    return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(kargs['dff'], activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(kargs['d_model'])  # (batch_size, seq_len, d_model)\n",
    "    ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Positional Encoding\n",
    "'''\n",
    "\n",
    "def get_angles(pos,i,d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2*i) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    # 포지션과 차원별로 각기 다른 값을 순차적으로 할당\n",
    "    angle_rads = get_angles(np.arange(position)[:,np.newaxis],\n",
    "                           np.arange(d_model)[np.newaxis,:],\n",
    "                            d_model\n",
    "                           )\n",
    "    \n",
    "    # 짝수차원에는 사인 함수, 홀수 차원에는 코사인 함수를 적용 \n",
    "    angle_rads[:,0::2] = np.sin(angle_rads[:,0::2])\n",
    "    angle_rads[:,1::2] = np.cos(angle_rads[:,1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, dtype= tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "인코더\n",
    "'''\n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kargs):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.mha = MultiHeadAttention(**kargs)\n",
    "        \n",
    "        self.ffn = point_wise_feed_forward_network(**kargs)\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(kargs['rate'])\n",
    "        self.dropout2 = tf.keras.layers.Dropout(kargs['rate'])\n",
    "        \n",
    "    def call(self, x, mask=None):\n",
    "        attn_output, _ = self.mha(x,x,x,mask)\n",
    "        attn_output = self.dropout1(attn_output)\n",
    "        out1 = self.layernorm1(x + attn_output)  # x를 그대로 더해줌 Residual Connection\n",
    "\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output)\n",
    "        out2 = self.layernorm2(out1 + ffn_output) \n",
    "        \n",
    "        return out2\n",
    "    \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kargs):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.d_model = kargs['d_model']\n",
    "        self.num_layers = kargs['num_layers']\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(kargs['input_vocab_size'], self.d_model)\n",
    "        self.pos_encoding = positional_encoding(kargs['maximum_position_encoding'], self.d_model)\n",
    "        \n",
    "        self.enc_layers = [EncoderLayer(**kargs) for _ in range(self.num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(kargs['rate'])\n",
    "        \n",
    "    def call(self,x,mask=None):\n",
    "        seq_len = tf.shape(x)[1] # 포지션 임베딩을 위함\n",
    "        # word embedding은  입력 길이가 가변적이고 포지션 임베딩인 고정이기 때문\n",
    "        \n",
    "        x= self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model,tf.float32)) # 임베딩에 대한 스케일을 맞추는 것\n",
    "        # 임베딩 차원의 제곱근 만큼 가중치 곱함\n",
    "        x += self.pos_encoding[:,:seq_len,:]\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x,mask)\n",
    "            \n",
    "        return x\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Decoder\n",
    "'''\n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kargs):\n",
    "        super(DecoderLayer,self).__init__()\n",
    "        \n",
    "        self.mha1 = MultiHeadAttention(**kargs)\n",
    "        self.mha2 = MultiHeadAttention(**kargs)\n",
    "        \n",
    "        self.ffn = point_wise_feed_forward_network(**kargs)\n",
    "        \n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        self.dropout1 = tf.keras.layers.Dropout(kargs['rate'])\n",
    "        self.dropout2 = tf.keras.layers.Dropout(kargs['rate'])\n",
    "        self.dropout3 = tf.keras.layers.Dropout(kargs['rate'])\n",
    "        \n",
    "    def call(self, x, enc_output, look_ahead_mask, padding_mask):\n",
    "        # 순방향 어텐션 마스크 look ahead mask 추가\n",
    "        attn1, attn_weights_block1 = self.mha1(x,x,x,look_ahead_mask)\n",
    "        attn1 = self.dropout1(attn1)\n",
    "        out1 = self.layernorm1(attn1 + x) # residual connection\n",
    "        \n",
    "        # encoder-decoder attention  : v, k , q -: Value, Key, Query 순 \n",
    "        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)\n",
    "        # decoder- self attention 결과 : Query, encoder  결과값 : value, key\n",
    "        # softmax(query*key)* value : Encoder에서 집중해야하는 포인트에 가중치를 줘서 가져오는 것\n",
    "        attn2 = self.dropout2(attn2)\n",
    "        out2 = self.layernorm2(attn2 + out1)\n",
    "        \n",
    "        ffn_output = self.ffn(out2)\n",
    "        ffn_output = self.dropout3(ffn_output)\n",
    "        \n",
    "        out3 = self.layernorm3(ffn_output + out2)\n",
    "        return out3, attn_weights_block1, attn_weights_block2\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kargs):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.d_model = kargs['d_model']\n",
    "        self.num_layers = kargs['num_layers']\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(kargs['target_vocab_size'], self.d_model)\n",
    "        self.pos_encoding = positional_encoding(kargs['maximum_position_encoding'], self.d_model)\n",
    "        \n",
    "        self.dec_layers = [DecoderLayer(**kargs) for _ in range(self.num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(kargs['rate'])\n",
    "        \n",
    "    def call(self,  x, enc_output, look_ahead_mask, padding_mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:,:seq_len,:]\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            # look_ahead_mask에 이미 상삼각행렬이 -로 처리 되어 있음 -- Matrix 형태\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, look_ahead_mask, padding_mask)\n",
    "            attention_weights['decoder_layer{}_block1'.format(i+1)]= block1\n",
    "            attention_weights['decoder_layer{}_block2'.format(i+1)]= block2\n",
    "            \n",
    "        return x, attention_weights\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Transformer Model\n",
    "'''\n",
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, **kargs):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.end_token_idx = kargs['end_token_idx']\n",
    "        \n",
    "        self.encoder = Encoder(**kargs)\n",
    "        self.decoder = Decoder(**kargs)\n",
    "        \n",
    "        self.final_layer = tf.keras.layers.Dense(kargs['target_vocab_size'])\n",
    "        \n",
    "    def call(self, x):\n",
    "        inp, tar = x\n",
    "        enc_padding_mask, look_ahead_mask, dec_padding_mask = create_masks(inp,tar)\n",
    "        enc_output = self.encoder(inp, enc_padding_mask)\n",
    "        dec_output, _ = self.decoder(\n",
    "                            tar, enc_output, look_ahead_mask, dec_padding_mask)\n",
    "        \n",
    "        final_output = self.final_layer(dec_output)\n",
    "        return final_output\n",
    "    \n",
    "    def inference(self,x):\n",
    "        inp = x\n",
    "        tar = tf.expand_dims([STD_INDEX],0) # start\n",
    "        \n",
    "        enc_padding_mask, look_ahead_mask, dec_padding_mask = create_masks(inp,tar)\n",
    "        enc_output = self.encoder(inp, enc_padding_mask)\n",
    "        \n",
    "        predict_tokens = list()\n",
    "        # 하나씩 반복해가면서 Inference\n",
    "        for t in range(0,MAX_SEQUENCE):\n",
    "            dec_output, _ = self.decoder(tar, enc_output, look_ahead_mask, dec_padding_mask)\n",
    "            final_output = self.final_layer(dec_output)\n",
    "            outputs = tf.argmax(final_output, -1).numpy()\n",
    "            pred_token = outputs[0][-1]\n",
    "            \n",
    "            if pred_token== self.end_token_idx:\n",
    "                break\n",
    "            predict_tokens.append(pred_token)\n",
    "            \n",
    "            tar = tf.expand_dims([STD_INDEX] + predict_tokens,0)\n",
    "            _, look_ahead_mask, dec_padding_mask = create_masks(inp, tar)\n",
    "            \n",
    "        return predict_tokens\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = prepro_configs['char2idx']\n",
    "end_index = prepro_configs['end_symbol']\n",
    "model_name = 'transformer'\n",
    "vocab_size = prepro_configs['vocab_size']\n",
    "BATCH_SIZE = 256\n",
    "MAX_SEQUENCE = 25\n",
    "EPOCHS = 200\n",
    "VALID_SPLIT = 0.1\n",
    "\n",
    "kargs = {#'model_name': model_name,\n",
    "        'num_layers': 2,\n",
    "        'd_model': 512,\n",
    "         'num_heads' : 8,\n",
    "         'dff' :2048,\n",
    "         'input_vocab_size': vocab_size,\n",
    "         'target_vocab_size' : vocab_size,\n",
    "         'maximum_position_encoding': MAX_SEQUENCE,\n",
    "         'end_token_idx' : word2idx[end_index],\n",
    "         'rate' : 0.1 #dropout        \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')\n",
    "\n",
    "def loss(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)\n",
    "\n",
    "def accuracy(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    mask = tf.expand_dims(tf.cast(mask, dtype=pred.dtype), axis=-1)\n",
    "    pred *= mask    \n",
    "    acc = train_accuracy(real, pred)\n",
    "\n",
    "    return tf.reduce_mean(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(**kargs)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              loss=loss,\n",
    "              metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_out/transformer -- Folder already exists \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# overfitting을 막기 위한 ealrystop 추가\n",
    "earlystop_callback = EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=10)\n",
    "# min_delta: the threshold that triggers the termination (acc should at least improve 0.0001)\n",
    "# patience: no improvment epochs (patience = 1, 1번 이상 상승이 없으면 종료)\n",
    "\n",
    "checkpoint_path = 'data_out/' + model_name + '/weights.h5'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create path if exists\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    print(\"{} -- Folder already exists \\n\".format(checkpoint_dir))\n",
    "else:\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    print(\"{} -- Folder create complete \\n\".format(checkpoint_dir))\n",
    "    \n",
    "\n",
    "cp_callback = ModelCheckpoint(\n",
    "    checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10640 samples, validate on 1183 samples\n",
      "Epoch 1/200\n",
      "10496/10640 [============================>.] - ETA: 0s - loss: 1.7962 - accuracy: 0.8099\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.81197, saving model to data_out/transformer/weights.h5\n",
      "10640/10640 [==============================] - 17s 2ms/sample - loss: 1.7911 - accuracy: 0.8100 - val_loss: 1.6897 - val_accuracy: 0.8120\n",
      "Epoch 2/200\n",
      "10496/10640 [============================>.] - ETA: 0s - loss: 1.3120 - accuracy: 0.8151\n",
      "Epoch 00002: val_accuracy improved from 0.81197 to 0.81986, saving model to data_out/transformer/weights.h5\n",
      "10640/10640 [==============================] - 11s 993us/sample - loss: 1.3109 - accuracy: 0.8152 - val_loss: 1.3980 - val_accuracy: 0.8199\n",
      "Epoch 3/200\n",
      "10496/10640 [============================>.] - ETA: 0s - loss: 1.1537 - accuracy: 0.8241\n",
      "Epoch 00003: val_accuracy improved from 0.81986 to 0.82721, saving model to data_out/transformer/weights.h5\n",
      "10640/10640 [==============================] - 11s 1ms/sample - loss: 1.1550 - accuracy: 0.8242 - val_loss: 1.3512 - val_accuracy: 0.8272\n",
      "Epoch 4/200\n",
      "10496/10640 [============================>.] - ETA: 0s - loss: 1.1129 - accuracy: 0.8297\n",
      "Epoch 00004: val_accuracy improved from 0.82721 to 0.83150, saving model to data_out/transformer/weights.h5\n",
      "10640/10640 [==============================] - 11s 1ms/sample - loss: 1.1136 - accuracy: 0.8298 - val_loss: 1.3289 - val_accuracy: 0.8315\n",
      "Epoch 5/200\n",
      "10496/10640 [============================>.] - ETA: 0s - loss: 1.0836 - accuracy: 0.8330\n",
      "Epoch 00005: val_accuracy improved from 0.83150 to 0.83434, saving model to data_out/transformer/weights.h5\n",
      "10640/10640 [==============================] - 11s 1ms/sample - loss: 1.0828 - accuracy: 0.8331 - val_loss: 1.3092 - val_accuracy: 0.8343\n",
      "Epoch 6/200\n",
      "10496/10640 [============================>.] - ETA: 0s - loss: 1.0526 - accuracy: 0.8354\n",
      "Epoch 00006: val_accuracy improved from 0.83434 to 0.83633, saving model to data_out/transformer/weights.h5\n",
      "10640/10640 [==============================] - 11s 1ms/sample - loss: 1.0524 - accuracy: 0.8355 - val_loss: 1.2867 - val_accuracy: 0.8363\n",
      "Epoch 7/200\n",
      "10496/10640 [============================>.] - ETA: 0s - loss: 1.0179 - accuracy: 0.8373\n",
      "Epoch 00007: val_accuracy improved from 0.83633 to 0.83809, saving model to data_out/transformer/weights.h5\n",
      "10640/10640 [==============================] - 11s 1ms/sample - loss: 1.0180 - accuracy: 0.8373 - val_loss: 1.2677 - val_accuracy: 0.8381\n",
      "Epoch 8/200\n",
      " 4864/10640 [============>.................] - ETA: 5s - loss: 0.9852 - accuracy: 0.8386"
     ]
    }
   ],
   "source": [
    "history = model.fit([index_inputs, index_outputs], index_targets, \n",
    "                    batch_size=BATCH_SIZE, epochs=EPOCHS,\n",
    "                    validation_split=VALID_SPLIT, callbacks=[earlystop_callback, cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.plot(history.history['val_'+string], '')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([string, 'val_'+string])\n",
    "    plt.show()\n",
    "plot_graphs(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_OUT_PATH = './data_out/'\n",
    "SAVE_FILE_NM = 'weights.h5'\n",
    "\n",
    "model.load_weights(os.path.join(DATA_OUT_PATH, model_name, SAVE_FILE_NM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx = prepro_configs['char2idx']\n",
    "idx2char = prepro_configs['idx2char']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"남자친구 승진 선물로 뭐가 좋을까?\"\n",
    "test_index_inputs, _ = enc_processing([text], char2idx)\n",
    "outputs = model.inference(test_index_inputs)\n",
    "\n",
    "print(' '.join([idx2char[str(o)] for o in outputs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
